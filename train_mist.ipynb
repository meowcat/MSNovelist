{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('/home/stravsmi/msmsgym/MSNovelist-private')\n",
    "\n",
    "\n",
    "from fp_management import database as db\n",
    "from fp_management import mist_fingerprinting as fpr\n",
    "from fp_management import fingerprint_map as fpm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import smiles_process as sp\n",
    "import importlib\n",
    "from importlib import reload\n",
    "import smiles_config as sc\n",
    "\n",
    "import infrastructure.generator as gen\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, \\\n",
    "    LambdaCallback, Callback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.config_file.append('config.MULTIUSR.yaml')\n",
    "sc.config_reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-May-24 13:04:21 - training startup\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup logger\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', \n",
    "                    datefmt='%d-%b-%y %H:%M:%S')\n",
    "logger = logging.getLogger(\"MSNovelist\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info(\"training startup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-May-24 13:04:22 - pipeline_x: ['fingerprint_selected', 'mol_form', 'tokens_X']\n",
      "31-May-24 13:04:22 - pipeline_y: ['tokens_y', 'n_hydrogen']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sampler_name = sc.config['sampler_name']\n",
    "sampler_module = None\n",
    "if sampler_name != '':\n",
    "    sampler_module = importlib.import_module('fp_sampling.' + sampler_name, 'fp_sampling')\n",
    "#import models.quicktrain_fw_20190327 as sm\n",
    "\n",
    "pipeline_x = sc.config['pipeline_x']\n",
    "pipeline_y = sc.config['pipeline_y']\n",
    "logger.info(f\"pipeline_x: {pipeline_x}\")\n",
    "logger.info(f\"pipeline_y: {pipeline_y}\")\n",
    "\n",
    "training_id = str(int(time.time()))\n",
    "if sc.config['training_id'] != '':\n",
    "    training_id = sc.config['training_id']\n",
    "\n",
    "sc.config.setdefault('cv_fold', 0)\n",
    "training_set = f\"train\"\n",
    "validation_set = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-May-24 13:04:22 - Training model id 1717153462, training set\n",
      "31-May-24 13:04:22 - Tag: m-1717153462-msnovelmist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.info(f\"Training model id {training_id}, training set\")\n",
    "\n",
    "model_tag_id = \"m-\" + training_id + \"-\" + sc.config['model_tag']\n",
    "logger.info(f\"Tag: {model_tag_id}\")\n",
    "\n",
    "weights_path = os.path.join(\n",
    "    sc.config[\"weights_folder\"],\n",
    "    model_tag_id,\n",
    "    \"train\")\n",
    "log_path = os.path.join(\n",
    "    sc.config['log_folder'],\n",
    "    model_tag_id,\n",
    "    \"train\")\n",
    "\n",
    "config_dump_path = os.path.join(\n",
    "    weights_path,\n",
    "    'config.yaml'\n",
    "    )\n",
    "\n",
    "os.makedirs(weights_path)\n",
    "os.makedirs(log_path)\n",
    "\n",
    "sc.config_dump(config_dump_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_folder': '/home/stravsmi/msmsgym/MSNovelist-private/',\n",
       " 'db_path': '',\n",
       " 'fp_source': '',\n",
       " 'fp_map': '/home/stravsmi/msmsgym/msnovelist-data/fingerprint_map_pseudo.tsv',\n",
       " 'epochs': 30,\n",
       " 'training_id': '',\n",
       " 'cv_fold': 1,\n",
       " 'cv_folds': 10,\n",
       " 'steps_per_epoch': -1,\n",
       " 'steps_per_epoch_validation': -1,\n",
       " 'batch_size': 256,\n",
       " 'hdf5_lock': 'FALSE',\n",
       " 'model_name': 'models.model_flex_20190401',\n",
       " 'sampler_name': 'gamma_bitmatrix',\n",
       " 'fingerprinter_path': '',\n",
       " 'fingerprinter_threads': 2,\n",
       " 'fingerprinter_cache': '/tmp/fingerprint_cache.db',\n",
       " 'weights_folder': '/target/evaluation/m-36719628/1',\n",
       " 'eval_folder': '/tmp/mistnovelist-eval/',\n",
       " 'log_folder': '/tmp/',\n",
       " 'weights': 'w-20-0.069-0.074.hdf5',\n",
       " 'sirius_bin': '/usr/local/bin/sirius',\n",
       " 'training_set': 'train',\n",
       " 'validation_set': 'validate',\n",
       " 'pipeline_x': ['fingerprint_selected', 'mol_form', 'tokens_X'],\n",
       " 'pipeline_y': ['tokens_y', 'n_hydrogen'],\n",
       " 'pipeline_x_eval': [],\n",
       " 'eval_n': 8,\n",
       " 'eval_n_total': 300,\n",
       " 'eval_k': 128,\n",
       " 'eval_kk': 128,\n",
       " 'eval_steps': 128,\n",
       " 'eval_id': '',\n",
       " 'eval_counter': '',\n",
       " 'eval_detail': False,\n",
       " 'eval_fingerprint_all': False,\n",
       " 'model_tag': 'msnovelmist',\n",
       " 'eval_top_n': 1,\n",
       " 'java_memory': 2048,\n",
       " 'fp_overlay_method': 'none',\n",
       " 'tensorflow_trace': False,\n",
       " 'training_verbose': 1,\n",
       " 'decoder_name': 'beam_search',\n",
       " 'random_seed_global': '',\n",
       " 'all_evaluation_sets': ['fold0-casmi',\n",
       "  'fold0-sirius',\n",
       "  'fold0-holdout',\n",
       "  'fold1-sirius',\n",
       "  'fold1-holdout',\n",
       "  'fold2-sirius',\n",
       "  'fold2-holdout',\n",
       "  'fold3-sirius',\n",
       "  'fold3-holdout',\n",
       "  'fold4-sirius',\n",
       "  'fold4-holdout',\n",
       "  'fold5-sirius',\n",
       "  'fold5-holdout',\n",
       "  'fold6-sirius',\n",
       "  'fold6-holdout',\n",
       "  'fold7-sirius',\n",
       "  'fold7-holdout',\n",
       "  'fold8-sirius',\n",
       "  'fold8-holdout',\n",
       "  'fold9-sirius',\n",
       "  'fold9-holdout'],\n",
       " 'db_path_train': {'construct_from': 'smiles',\n",
       "  'fp_map': '/home/stravsmi/msmsgym/msnovelist-data/fingerprint_map_pseudo.tsv',\n",
       "  'path': '/home/stravsmi/msmsgym/msnovelist-data/mist-9652ac1e-0a8f-4ad0-b622-8092332976d7.db',\n",
       "  'pipeline_options': {'embed_X': False,\n",
       "   'fingerprint_selected': 'fingerprint_sampled'},\n",
       "  'reload_smiles_pubchem': False},\n",
       " 'db_path_eval': {'construct_from': 'smiles',\n",
       "  'fp_map': '/home/stravsmi/msmsgym/msnovelist-data/fingerprint_map_pseudo.tsv',\n",
       "  'path': '/home/stravsmi/msmsgym/msnovelist-data/mist-val-e76ec6be-057a-4207-b46d-6ba1b867c7f9.db',\n",
       "  'pipeline_options': {'embed_X': False,\n",
       "   'fingerprint_selected': 'fingerprint_degraded'},\n",
       "  'reload_smiles_pubchem': False},\n",
       " 'db_path_sampler': {'construct_from': 'smiles',\n",
       "  'fp_map': '/home/stravsmi/msmsgym/msnovelist-data/fingerprint_map_pseudo.tsv',\n",
       "  'path': '/home/stravsmi/msmsgym/msnovelist-data/mist-val-e76ec6be-057a-4207-b46d-6ba1b867c7f9.db',\n",
       "  'pipeline_options': {'embed_X': False},\n",
       "  'reload_smiles_pubchem': False},\n",
       " 'db_pubchem': '/msnovelist/data/pubchem-dummy/pubchem_ref_dummy.db',\n",
       " 'decoder_config': {'clip_invalid_counts': False,\n",
       "  'tokenization': 'tokens_process'},\n",
       " 'eval_temperature': 1.0,\n",
       " 'evaluation_set': 'dataset',\n",
       " 'f1_cutoff': 0.5,\n",
       " 'normalizer_path': '/contrib/fingerprinter_cli/bin/smiles_normalizer',\n",
       " 'sirius_path': '/contrib/sirius/bin/sirius',\n",
       " 'fp_map_evaluation': '/home/stravsmi/msmsgym/msnovelist-data/fingerprint_map_pseudo.tsv',\n",
       " 'model_config': {'loss_weights': {'out_nhydrogen': 0.03, 'out_smiles': 1},\n",
       "  'use_auxiliary_counter': True,\n",
       "  'use_fingerprint': True,\n",
       "  'use_hydrogen_estimator': True,\n",
       "  'encoder_dropout': [0.3, 0.3],\n",
       "  'encoder_input_dropout': 'None'},\n",
       " 'pipeline_encoder': ['fingerprint_selected', 'mol_form', 'n_hydrogen'],\n",
       " 'pipeline_reference': ['smiles_canonical', 'fingerprint_degraded'],\n",
       " 'rerank_sirius_results_n': 99999,\n",
       " 'sampler_config': {'mean': 0,\n",
       "  'stddev': 2,\n",
       "  'reverse_0_stats': False,\n",
       "  'unchanged_rate': 0.05}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-May-24 13:14:04 - Datasets - loading database\n",
      "31-May-24 13:16:03 - Datasets - loading evaluation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "logger.info(f\"Datasets - loading database\")\n",
    "fp_db  = db.FpDatabase.load_from_config(sc.config['db_path_train'])\n",
    "fp_train = fp_db.get_grp(training_set)\n",
    "fp_val = fp_db.get_grp(validation_set)\n",
    "logger.info(f\"Datasets - loading evaluation\")\n",
    "# File for CSI:FingerID validation data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_eval_ =  sc.config[\"db_path_eval\"]\n",
    "# note: with CV, the evaluation set name is the same as the validation set name\n",
    "db_eval = db.FpDatabase.load_from_config(data_eval_)\n",
    "dataset_eval = db_eval.get_grp(validation_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro = next(iter(fp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr.MistFingerprinter.init_instance()\n",
    "fingerprinter = fpr.MistFingerprinter.get_instance()\n",
    "fpfp = fingerprinter.get_fp(ro[\"fingerprint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embed_X': False, 'fingerprint_selected': 'fingerprint_sampled'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_db.get_pipeline_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-May-24 13:24:53 - Datasets - building pipeline for database\n",
      "/home/stravsmi/msmsgym/MSNovelist-private/infrastructure/generator.py:98: UserWarning: Degraded fingerprints not in dataset, using regular fingerprints\n",
      "  warnings.warn(\"Degraded fingerprints not in dataset, using regular fingerprints\")\n",
      "31-May-24 13:25:09 - using unpickle_mf\n",
      "31-May-24 13:25:48 - not using unpack\n",
      "31-May-24 13:25:48 - not using fp_map\n",
      "31-May-24 13:25:49 - not using embed_X\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.info(f\"Datasets - building pipeline for database\")\n",
    "\n",
    "\n",
    "fp_dataset_train_ = gen.smiles_pipeline(fp_train, \n",
    "                                        batch_size = sc.config['batch_size'],\n",
    "                                        map_fingerprints=False,\n",
    "                                        **fp_db.get_pipeline_options())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fingerprint': <MapDataset shapes: (None,), types: tf.float32>,\n",
       " 'fingerprint_degraded': <MapDataset shapes: (None,), types: tf.float32>,\n",
       " 'mol_form': <MapDataset shapes: (None, 10), types: tf.float32>,\n",
       " 'smiles_generic': <MapDataset shapes: (None,), types: tf.string>,\n",
       " 'smiles_canonical': <MapDataset shapes: (None,), types: tf.string>,\n",
       " 'n_hydrogen': <MapDataset shapes: (None,), types: tf.float32>,\n",
       " 'tokens_X': <MapDataset shapes: (None, None, 40), types: tf.float32>,\n",
       " 'tokens_y': <MapDataset shapes: (None, None, 40), types: tf.float32>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_dataset_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fp_dataset_val_ = gen.smiles_pipeline(fp_val, \n",
    "                                        batch_size = sc.config['batch_size'],\n",
    "                                        map_fingerprints=False,\n",
    "                                        **fp_db.get_pipeline_options())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger.info(f\"Datasets - building pipeline for evaluation\")\n",
    "fp_dataset_eval_ = gen.smiles_pipeline(dataset_eval, \n",
    "                                    batch_size = sc.config['batch_size'],\n",
    "                                    map_fingerprints=False,\n",
    "                                    **db_eval.get_pipeline_options())\n",
    "\n",
    "logger.info(f\"Datasets - pipelines built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 684), dtype=float32, numpy=\n",
       "array([[65., 65., 65., ..., 65., 65., 61.],\n",
       "       [65., 65., 65., ..., 65., 65., 61.],\n",
       "       [65., 65., 67., ..., 65., 65., 61.],\n",
       "       ...,\n",
       "       [65., 65., 65., ..., 65., 65., 61.],\n",
       "       [65., 67., 65., ..., 65., 65., 61.],\n",
       "       [65., 65., 65., ..., 65., 65., 61.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(fp_dataset_train_['fingerprint']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If fingerprint sampling is configured: load the sampler and map it\n",
    "if sampler_module is not None:\n",
    "    logger.info(f\"Sampler {sampler_name} loading\")\n",
    "    sampler_factory = sampler_module.SamplerFactory(sc.config)\n",
    "    sampler = sampler_factory.get_sampler()\n",
    "    logger.info(f\"Sampler {sampler_name} loaded\")\n",
    "    fp_dataset_train_ = sampler.map_dataset(fp_dataset_train_)\n",
    "    fp_dataset_val_ = sampler.map_dataset(fp_dataset_val_)\n",
    "\n",
    "fp_dataset_train = gen.dataset_zip(fp_dataset_train_, pipeline_x, pipeline_y,\n",
    "                                   **fp_db.get_pipeline_options())\n",
    "fp_dataset_train = fp_dataset_train.repeat(sc.config['epochs'])\n",
    "fp_dataset_train = fp_dataset_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "blueprints = gen.dataset_blueprint(fp_dataset_train_)\n",
    "\n",
    "fp_dataset_val = gen.dataset_zip(fp_dataset_val_, pipeline_x, pipeline_y,\n",
    "                                 **fp_db.get_pipeline_options())\n",
    "fp_dataset_val = fp_dataset_val.repeat(sc.config['epochs'])\n",
    "fp_dataset_val = fp_dataset_val.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "fp_dataset_eval = gen.dataset_zip(fp_dataset_eval_, pipeline_x, pipeline_y,\n",
    "                                  **db_eval.get_pipeline_options())\n",
    "fp_dataset_eval = fp_dataset_eval.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "training_total = len(fp_train)\n",
    "validation_total= len(fp_val)\n",
    "training_steps = math.floor(training_total /  sc.config['batch_size'])\n",
    "if sc.config['steps_per_epoch'] > 0:\n",
    "    training_steps = sc.config['steps_per_epoch']\n",
    "\n",
    "validation_steps = math.floor(validation_total /  sc.config['batch_size'])\n",
    "if sc.config['steps_per_epoch_validation'] > 0:\n",
    "    validation_steps = sc.config['steps_per_epoch_validation']\n",
    "    \n",
    "batch_size = sc.config[\"batch_size\"]\n",
    "epochs=sc.config['epochs']\n",
    "\n",
    "logger.info(f\"Preparing training: {epochs} epochs, {training_steps} steps per epoch, batch size {batch_size}\")\n",
    "\n",
    "\n",
    "round_fingerprints = False\n",
    "if sampler_name != '':\n",
    "    round_fingerprints = sampler_factory.round_fingerprint_inference()\n",
    "\n",
    "import model\n",
    "transcoder_model = model.TranscoderModel(\n",
    "    blueprints = blueprints,\n",
    "    config = sc.config,\n",
    "    round_fingerprints = round_fingerprints\n",
    "    )\n",
    "\n",
    "initial_epoch = 0\n",
    "\n",
    "\n",
    "logger.info(\"Building model\")\n",
    "\n",
    "transcoder_model.compile()\n",
    "#\n",
    "# If set correspondingly: load weights and continue training\n",
    "if 'continue_training_epoch' in sc.config: \n",
    "    if sc.config['continue_training_epoch'] > 0:\n",
    "        transcoder_model.load_weights(os.path.join(\n",
    "            sc.config['weights_folder'],\n",
    "            sc.config['weights']))\n",
    "        transcoder_model._make_train_function()\n",
    "        with open(os.path.join(\n",
    "                sc.config['weights_folder'],\n",
    "                sc.config['weights_optimizer']), 'rb') as f:\n",
    "            weight_values = pickle.load(f)\n",
    "        transcoder_model.optimizer.set_weights(weight_values)\n",
    "        initial_epoch = sc.config['continue_training_epoch']\n",
    "\n",
    "\n",
    "logger.info(\"Model built\")\n",
    "# {eval_loss:.3f}\n",
    "filepath= os.path.join(\n",
    "    weights_path,\n",
    "    \"w-{epoch:02d}-{loss:.3f}-{val_loss:.3f}.hdf5\"\n",
    "    )\n",
    "\n",
    "\n",
    "tensorflow_trace = sc.config[\"tensorflow_trace\"]\n",
    "if tensorflow_trace:\n",
    "    tensorboard_profile_batch = 2\n",
    "else:\n",
    "    tensorboard_profile_batch = 0\n",
    "verbose = sc.config[\"training_verbose\"]\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', \n",
    "                             save_weights_only=True)\n",
    "tensorboard = TensorBoard(log_dir=log_path, \n",
    "                          histogram_freq=1,  \n",
    "                          profile_batch = tensorboard_profile_batch,\n",
    "                          write_graph=tensorflow_trace,\n",
    "                          write_images=tensorflow_trace)\n",
    "\n",
    "save_optimizer = model.resources.SaveOptimizerCallback(weights_path)\n",
    "evaluation = model.resources.AdditionalValidationSet(fp_dataset_eval, \n",
    "                                                     \"eval\", \n",
    "                                                     verbose = 0)\n",
    "\n",
    "print_logs = LambdaCallback(\n",
    "    on_epoch_end = lambda epoch, logs: print(logs)\n",
    "    )\n",
    "\n",
    "json_log = open(os.path.join(weights_path, 'loss_log.json'),\n",
    " mode='wt', buffering=1)\n",
    "json_logging_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: json_log.write(\n",
    "        json.dumps({'epoch': epoch, 'loss': logs}) + '\\n'),\n",
    "    on_train_end=lambda logs: json_log.close()\n",
    ")\n",
    "#\n",
    "\n",
    "callbacks_list = [evaluation, \n",
    "                  tensorboard, \n",
    "                  print_logs, \n",
    "                  json_logging_callback,\n",
    "                  checkpoint, \n",
    "                  save_optimizer]\n",
    "\n",
    "logger.info(\"Training - start\")\n",
    "transcoder_model.fit(x=fp_dataset_train, \n",
    "          epochs=epochs, \n",
    "          #batch_size=sc.config['batch_size'],\n",
    "          steps_per_epoch=training_steps,\n",
    "          callbacks = callbacks_list,\n",
    "          validation_data = fp_dataset_val,\n",
    "          validation_steps = validation_steps,\n",
    "          initial_epoch = initial_epoch,\n",
    "          verbose = verbose)\n",
    "logger.info(\"Training - done\")\n",
    "fp_db.close()\n",
    "\n",
    "logger.info(\"training end\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
